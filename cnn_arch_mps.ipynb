{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin: auto; border-radius: 50%;\" src=\"https://yt3.ggpht.com/SQPVly-us6iK-A-3PK4nwzZjzoXAdJU1pN1YKeYkyCQoIGWdAcKSVbbnmjpBGmcMdsLxu4doTg=s600-c-k-c0x00ffffff-no-rj-rp-mo\" width=\"100px\" height=\"100px\">\n",
    "\n",
    "<h3>Convolutional Neural Network for Image Classification [PyTORCH + CUSTOM ARCH + MAC M3 MPS] -- [VR Imersed]</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/channel/UCeS3HdDzVUCfl8WsOExR-UA\n",
    "\n",
    "Subscribe for more videos\n",
    "\n",
    "Links:</br>\n",
    "https://www.kaggle.com/datasets/apollo2506/eurosat-dataset</br>\n",
    "https://pytorch.org/docs/stable/notes/mps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opendatasets numpy matplotlib tqdm torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import opendatasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as functional\n",
    "from torch import optim as optim\n",
    "from torchvision import transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for MPS (Metal Performance Shaders) - MAC's GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS device not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the DataSet from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opendatasets.download(\"https://www.kaggle.com/datasets/apollo2506/eurosat-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./eurosat-dataset/EuroSAT\"\n",
    "train_dataset_dir = \"./data/train\"\n",
    "test_dataset_dir = \"./data/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [dir_name for dir_name in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, dir_name))]\n",
    "classes.sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train and test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir is empty xD\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(train_dataset_dir)\n",
    "    shutil.rmtree(test_dataset_dir)\n",
    "except:\n",
    "    print(\"Working dir is empty xD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(train_dataset_dir)\n",
    "os.makedirs(test_dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map class names by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = { \n",
    "    0:'AnnualCrop',\n",
    "    1:'Forest',\n",
    "    2:'HerbaceousVegetation',\n",
    "    3:'Highway',\n",
    "    4:'Industrial',\n",
    "    5:'Pasture',\n",
    "    6:'PermanentCrop',\n",
    "    7:'Residential',\n",
    "    8:'River',\n",
    "    9:'SeaLake'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data onto train and test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_names = []\n",
    "test_image_names = []\n",
    "cur_class_index = 0\n",
    "\n",
    "for class_name in classes:\n",
    "    if class_name != \".\":\n",
    "        image_list_for_class = os.listdir(os.path.join(dataset_dir, class_name))\n",
    "        sample_size = int(len(image_list_for_class) * 0.8)\n",
    "        train_dir_class = os.path.join(train_dataset_dir, str(cur_class_index))\n",
    "        os.mkdir(train_dir_class)\n",
    "        for image_name in random.sample(image_list_for_class, sample_size):\n",
    "            shutil.copy2(os.path.join(dataset_dir, class_name, image_name), train_dir_class)\n",
    "            train_image_names.append(image_name)\n",
    "\n",
    "        test_dir_class = os.path.join(test_dataset_dir, str(cur_class_index))\n",
    "        test_image_names = list(set(image_list_for_class) - set(train_image_names))\n",
    "        os.mkdir(test_dir_class)\n",
    "        for image_name in test_image_names:\n",
    "            shutil.copy2(os.path.join(dataset_dir, class_name, image_name), test_dir_class)\n",
    "        \n",
    "        cur_class_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing and data loader creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect to have images with the same dimension and scale to feed the model \n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root=train_dataset_dir, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(root=test_dataset_dir, transform=transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_dataloader))\n",
    "print(\"Image count:\", len(images), \"Label count:\", len(labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(torchvision.utils.make_grid(images[:8]))\n",
    "print(\"Labels: \", ' '.join('%d' % labels[j] for j in range(8)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeSpaceNet(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(CodeSpaceNet, self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, 1)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(215296, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features (borders, textures, shapes...) of images by applying filters (kernels)\n",
    "        x = self.conv1(x)\n",
    "        # The ReLU activation function introduces the property of nonlinearity \n",
    "        # and solves the vanishing gradients issue\n",
    "        x = functional.relu(x) \n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = functional.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = functional.relu(x)\n",
    "        # Selects the maximum element from the region of the feature map covered by the filter.\n",
    "        # It reduces the spatial dimensions of features by selecting the maximum value within each small window or region.\n",
    "        x = functional.max_pool2d(x, 2)\n",
    "        # A regularization technique to prevent overtitting during the trainning process.\n",
    "        # It randomly discharges some neurons outpus.\n",
    "        x = self.dropout1(x)\n",
    "        # Reshape the tensor to feed fc.\n",
    "        x = torch.flatten(x, 1)\n",
    "        # It works like a MLP classifier. Each neuron of the layer is connection to all neurons of the previous layer.\n",
    "        x = self.fc1(x)\n",
    "        x = functional.relu(x)\n",
    "        x = self.dropout2(x) # Generally used before fc to reduce dependency between neurons.\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = functional.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = functional.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        # Calculates a probability for every possible class.\n",
    "        return functional.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CodeSpaceNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train start\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    start = time.time()    \n",
    "    \n",
    "    for data in (pbar := tqdm(train_dataloader)):\n",
    "        pbar.set_description(f\"\\nEpoch {epoch} GPU Mem.: {round(torch.mps.current_allocated_memory() / 1024 / 1024 / 1024, 2)} GB\") \n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Back propagates loss to calculate the gradient.\n",
    "        loss.backward()\n",
    "        # Updatesthe neural network weights.\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        if i % 100 == 0:\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                test_images, test_labels = next(test_iter)\n",
    "                test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "                test_outputs = model(test_images[:8])\n",
    "\n",
    "                _, predicted = torch.max(test_outputs, 1)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Epoch {epoch}, Loss: {running_loss / (i)}, Time: {round((end - start) / 60, 2)} min.\")\n",
    "\n",
    "print(\"Train stop\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corect = 0\n",
    "total_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data in (pbar := tqdm(test_dataloader)):\n",
    "\n",
    "        pbar.set_description(f\"Model eval.\")\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = total_correct / total_samples\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    data_iter = iter(test_dataloader)\n",
    "    data = next(data_iter)\n",
    "\n",
    "    inputs, _ = data\n",
    "\n",
    "    image = inputs[0].unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "\n",
    "    outputs = model(image)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    np_img = image.cpu().numpy()[0]\n",
    "\n",
    "    np_img = np.transpose(np_img, (1, 2, 0))\n",
    "\n",
    "    if np_img.shape[2] == 1:\n",
    "        np_img = np.squeeze(np_img, axis=2)\n",
    "    elif np_img.shape[2] == 3:\n",
    "        np_img = (np_img - np_img.min()) / (np_img.max() - np_img.min())\n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(np_img)\n",
    "    plt.title(class_map[predicted.item()])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "stop = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
